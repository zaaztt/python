{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用SGD分类器和回归方法对星际争霸2玩家段位预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、利用SGD分类器进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "import pyparsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GameID</th>\n",
       "      <th>LeagueIndex</th>\n",
       "      <th>Age</th>\n",
       "      <th>HoursPerWeek</th>\n",
       "      <th>TotalHours</th>\n",
       "      <th>APM</th>\n",
       "      <th>SelectByHotkeys</th>\n",
       "      <th>AssignToHotkeys</th>\n",
       "      <th>UniqueHotkeys</th>\n",
       "      <th>MinimapAttacks</th>\n",
       "      <th>MinimapRightClicks</th>\n",
       "      <th>NumberOfPACs</th>\n",
       "      <th>GapBetweenPACs</th>\n",
       "      <th>ActionLatency</th>\n",
       "      <th>ActionsInPAC</th>\n",
       "      <th>TotalMapExplored</th>\n",
       "      <th>WorkersMade</th>\n",
       "      <th>UniqueUnitsMade</th>\n",
       "      <th>ComplexUnitsMade</th>\n",
       "      <th>ComplexAbilitiesUsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>3000</td>\n",
       "      <td>143.7180</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>32.6677</td>\n",
       "      <td>40.8673</td>\n",
       "      <td>4.7508</td>\n",
       "      <td>28</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>5000</td>\n",
       "      <td>129.2322</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>32.9194</td>\n",
       "      <td>42.3454</td>\n",
       "      <td>4.8434</td>\n",
       "      <td>22</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>69.9612</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>44.6475</td>\n",
       "      <td>75.3548</td>\n",
       "      <td>4.0430</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>400</td>\n",
       "      <td>107.6016</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>29.2203</td>\n",
       "      <td>53.7352</td>\n",
       "      <td>4.9155</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>122.8908</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>22.6885</td>\n",
       "      <td>62.0813</td>\n",
       "      <td>9.3740</td>\n",
       "      <td>15</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>70</td>\n",
       "      <td>44.4570</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>76.4405</td>\n",
       "      <td>98.7719</td>\n",
       "      <td>3.0965</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>240</td>\n",
       "      <td>46.9962</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>94.0227</td>\n",
       "      <td>90.5311</td>\n",
       "      <td>4.1017</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>42</td>\n",
       "      <td>10000</td>\n",
       "      <td>212.6022</td>\n",
       "      <td>0.009040</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>6</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.004952</td>\n",
       "      <td>24.6117</td>\n",
       "      <td>41.7671</td>\n",
       "      <td>6.6104</td>\n",
       "      <td>45</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>77</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>2708</td>\n",
       "      <td>117.4884</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.005399</td>\n",
       "      <td>52.0140</td>\n",
       "      <td>46.4321</td>\n",
       "      <td>3.3746</td>\n",
       "      <td>29</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>800</td>\n",
       "      <td>155.9856</td>\n",
       "      <td>0.005054</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.003569</td>\n",
       "      <td>24.4632</td>\n",
       "      <td>52.1538</td>\n",
       "      <td>6.5664</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>6000</td>\n",
       "      <td>153.8010</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.003772</td>\n",
       "      <td>23.4107</td>\n",
       "      <td>48.0711</td>\n",
       "      <td>7.0044</td>\n",
       "      <td>24</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>190</td>\n",
       "      <td>79.2948</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>39.6381</td>\n",
       "      <td>65.5000</td>\n",
       "      <td>4.2269</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>97</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>350</td>\n",
       "      <td>67.4754</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.002885</td>\n",
       "      <td>42.4370</td>\n",
       "      <td>68.0502</td>\n",
       "      <td>4.3222</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "      <td>119.4366</td>\n",
       "      <td>0.004952</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>54.8718</td>\n",
       "      <td>79.2102</td>\n",
       "      <td>6.2293</td>\n",
       "      <td>21</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>5000</td>\n",
       "      <td>160.4754</td>\n",
       "      <td>0.004254</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>36.2897</td>\n",
       "      <td>46.8889</td>\n",
       "      <td>5.4361</td>\n",
       "      <td>28</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>102</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>1500</td>\n",
       "      <td>81.7722</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>45.1654</td>\n",
       "      <td>64.7500</td>\n",
       "      <td>4.5312</td>\n",
       "      <td>15</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>105</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>2000</td>\n",
       "      <td>50.8374</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.002656</td>\n",
       "      <td>45.7902</td>\n",
       "      <td>76.8889</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>106</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>160.6464</td>\n",
       "      <td>0.003430</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.005535</td>\n",
       "      <td>28.3636</td>\n",
       "      <td>37.7947</td>\n",
       "      <td>4.7671</td>\n",
       "      <td>29</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>118</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>350</td>\n",
       "      <td>107.9118</td>\n",
       "      <td>0.006701</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.003237</td>\n",
       "      <td>67.0744</td>\n",
       "      <td>71.3251</td>\n",
       "      <td>4.3786</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>127</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>1100</td>\n",
       "      <td>114.7806</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>40.4427</td>\n",
       "      <td>59.9370</td>\n",
       "      <td>4.9961</td>\n",
       "      <td>16</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>132</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>115.1274</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>30.7660</td>\n",
       "      <td>49.4854</td>\n",
       "      <td>4.6790</td>\n",
       "      <td>30</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>138</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>500</td>\n",
       "      <td>133.7016</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>21.4686</td>\n",
       "      <td>50.5253</td>\n",
       "      <td>5.4892</td>\n",
       "      <td>29</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>139</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>800</td>\n",
       "      <td>99.5088</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>22.7265</td>\n",
       "      <td>68.7321</td>\n",
       "      <td>6.7054</td>\n",
       "      <td>23</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>140</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>83.9172</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004607</td>\n",
       "      <td>51.2082</td>\n",
       "      <td>52.0494</td>\n",
       "      <td>2.8663</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>141</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>500</td>\n",
       "      <td>216.6936</td>\n",
       "      <td>0.012495</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.004334</td>\n",
       "      <td>27.9255</td>\n",
       "      <td>45.1605</td>\n",
       "      <td>6.3395</td>\n",
       "      <td>18</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>142</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>800</td>\n",
       "      <td>129.8598</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>36.3934</td>\n",
       "      <td>57.5215</td>\n",
       "      <td>6.7587</td>\n",
       "      <td>36</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.001229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>144</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>70</td>\n",
       "      <td>2520</td>\n",
       "      <td>267.5586</td>\n",
       "      <td>0.027815</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.005616</td>\n",
       "      <td>34.6035</td>\n",
       "      <td>40.6025</td>\n",
       "      <td>4.1629</td>\n",
       "      <td>36</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>149</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>800</td>\n",
       "      <td>74.1174</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>46.4122</td>\n",
       "      <td>71.8173</td>\n",
       "      <td>3.7944</td>\n",
       "      <td>34</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>154</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>700</td>\n",
       "      <td>101.6796</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>26.7979</td>\n",
       "      <td>54.5979</td>\n",
       "      <td>5.3144</td>\n",
       "      <td>22</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>158</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>160</td>\n",
       "      <td>150.5004</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.004626</td>\n",
       "      <td>30.2222</td>\n",
       "      <td>45.5941</td>\n",
       "      <td>4.9077</td>\n",
       "      <td>14</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3307</th>\n",
       "      <td>9213</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>364</td>\n",
       "      <td>77.5512</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>31.8431</td>\n",
       "      <td>65.8701</td>\n",
       "      <td>4.9740</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>9215</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>700</td>\n",
       "      <td>107.2092</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>33.5566</td>\n",
       "      <td>62.9165</td>\n",
       "      <td>4.4921</td>\n",
       "      <td>35</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>9216</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>240</td>\n",
       "      <td>54.8400</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>52.1553</td>\n",
       "      <td>97.3462</td>\n",
       "      <td>5.2981</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>9218</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>350</td>\n",
       "      <td>129.9708</td>\n",
       "      <td>0.003898</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>32.7975</td>\n",
       "      <td>48.5749</td>\n",
       "      <td>5.5657</td>\n",
       "      <td>17</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>9219</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>80.4000</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.002520</td>\n",
       "      <td>45.2596</td>\n",
       "      <td>85.1695</td>\n",
       "      <td>5.8390</td>\n",
       "      <td>23</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>9223</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>730</td>\n",
       "      <td>233.4966</td>\n",
       "      <td>0.014179</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.005570</td>\n",
       "      <td>28.2072</td>\n",
       "      <td>33.7304</td>\n",
       "      <td>5.0392</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>9224</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>74.3232</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>44.2868</td>\n",
       "      <td>77.9549</td>\n",
       "      <td>5.2820</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>9225</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>146.3508</td>\n",
       "      <td>0.005753</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>31.3962</td>\n",
       "      <td>61.9098</td>\n",
       "      <td>7.0414</td>\n",
       "      <td>29</td>\n",
       "      <td>0.001642</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>9228</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>49.0470</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.002284</td>\n",
       "      <td>37.5909</td>\n",
       "      <td>83.0734</td>\n",
       "      <td>3.9379</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3316</th>\n",
       "      <td>9230</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>56</td>\n",
       "      <td>100.5414</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>39.9604</td>\n",
       "      <td>57.3725</td>\n",
       "      <td>7.2353</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3317</th>\n",
       "      <td>9232</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>400</td>\n",
       "      <td>61.3848</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>40.3259</td>\n",
       "      <td>76.5294</td>\n",
       "      <td>4.7941</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318</th>\n",
       "      <td>9234</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>1000</td>\n",
       "      <td>209.1480</td>\n",
       "      <td>0.021344</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>50.9589</td>\n",
       "      <td>80.9730</td>\n",
       "      <td>6.8784</td>\n",
       "      <td>14</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3319</th>\n",
       "      <td>9236</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>1200</td>\n",
       "      <td>65.6622</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>58.3597</td>\n",
       "      <td>73.8571</td>\n",
       "      <td>3.5286</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3320</th>\n",
       "      <td>9237</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>730</td>\n",
       "      <td>173.9034</td>\n",
       "      <td>0.008175</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.003529</td>\n",
       "      <td>44.3032</td>\n",
       "      <td>59.6978</td>\n",
       "      <td>6.9820</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3321</th>\n",
       "      <td>9240</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>750</td>\n",
       "      <td>89.2404</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>43.7527</td>\n",
       "      <td>60.5072</td>\n",
       "      <td>4.4384</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>9243</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>60</td>\n",
       "      <td>95.5152</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>29.6667</td>\n",
       "      <td>87.4466</td>\n",
       "      <td>8.4704</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3323</th>\n",
       "      <td>9244</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>600</td>\n",
       "      <td>88.5822</td>\n",
       "      <td>0.003338</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.002718</td>\n",
       "      <td>41.8625</td>\n",
       "      <td>65.7427</td>\n",
       "      <td>5.1115</td>\n",
       "      <td>30</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3324</th>\n",
       "      <td>9245</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>131.0706</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>24.6410</td>\n",
       "      <td>47.6308</td>\n",
       "      <td>4.3754</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3325</th>\n",
       "      <td>9246</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>830</td>\n",
       "      <td>152.1852</td>\n",
       "      <td>0.011256</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>61.6421</td>\n",
       "      <td>64.3979</td>\n",
       "      <td>5.0733</td>\n",
       "      <td>15</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3326</th>\n",
       "      <td>9247</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>117.6942</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>35.9184</td>\n",
       "      <td>65.7374</td>\n",
       "      <td>6.5859</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3327</th>\n",
       "      <td>9251</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>650</td>\n",
       "      <td>53.6844</td>\n",
       "      <td>0.003303</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>43.5214</td>\n",
       "      <td>98.7458</td>\n",
       "      <td>3.7288</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>9253</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>500</td>\n",
       "      <td>216.4782</td>\n",
       "      <td>0.017363</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>36.8101</td>\n",
       "      <td>54.6162</td>\n",
       "      <td>6.5126</td>\n",
       "      <td>24</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>9255</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>2000</td>\n",
       "      <td>278.2188</td>\n",
       "      <td>0.026177</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.004244</td>\n",
       "      <td>30.4828</td>\n",
       "      <td>47.4678</td>\n",
       "      <td>6.0901</td>\n",
       "      <td>22</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>9256</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>560</td>\n",
       "      <td>88.4742</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>34.0286</td>\n",
       "      <td>63.7720</td>\n",
       "      <td>4.3420</td>\n",
       "      <td>29</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>9260</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>36</td>\n",
       "      <td>1500</td>\n",
       "      <td>96.6198</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>47.2967</td>\n",
       "      <td>82.3825</td>\n",
       "      <td>6.0383</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>9261</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>400</td>\n",
       "      <td>158.1390</td>\n",
       "      <td>0.013829</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.003583</td>\n",
       "      <td>36.3990</td>\n",
       "      <td>66.2718</td>\n",
       "      <td>4.5097</td>\n",
       "      <td>30</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3333</th>\n",
       "      <td>9264</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>56</td>\n",
       "      <td>1500</td>\n",
       "      <td>186.1320</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.005414</td>\n",
       "      <td>22.8615</td>\n",
       "      <td>34.7417</td>\n",
       "      <td>4.9309</td>\n",
       "      <td>38</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>9265</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>121.6992</td>\n",
       "      <td>0.002956</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>35.5833</td>\n",
       "      <td>57.9585</td>\n",
       "      <td>5.4154</td>\n",
       "      <td>23</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3335</th>\n",
       "      <td>9270</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>400</td>\n",
       "      <td>134.2848</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.003205</td>\n",
       "      <td>18.2927</td>\n",
       "      <td>62.4615</td>\n",
       "      <td>6.0202</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3336</th>\n",
       "      <td>9271</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>400</td>\n",
       "      <td>88.8246</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>45.1512</td>\n",
       "      <td>63.4435</td>\n",
       "      <td>5.1913</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3337 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GameID  LeagueIndex  Age  HoursPerWeek  TotalHours       APM  \\\n",
       "0         52            5   27            10        3000  143.7180   \n",
       "1         55            5   23            10        5000  129.2322   \n",
       "2         56            4   30            10         200   69.9612   \n",
       "3         57            3   19            20         400  107.6016   \n",
       "4         58            3   32            10         500  122.8908   \n",
       "5         60            2   27             6          70   44.4570   \n",
       "6         61            1   21             8         240   46.9962   \n",
       "7         72            7   17            42       10000  212.6022   \n",
       "8         77            4   20            14        2708  117.4884   \n",
       "9         81            4   18            24         800  155.9856   \n",
       "10        83            3   16            16        6000  153.8010   \n",
       "11        93            4   26             4         190   79.2948   \n",
       "12        97            3   18            12         350   67.4754   \n",
       "13        98            3   38             6        1000  119.4366   \n",
       "14       100            5   16            30        5000  160.4754   \n",
       "15       102            5   17            16        1500   81.7722   \n",
       "16       105            4   28             8        2000   50.8374   \n",
       "17       106            5   20            10         120  160.6464   \n",
       "18       118            5   16            14         350  107.9118   \n",
       "19       127            4   26            28        1100  114.7806   \n",
       "20       132            5   21            10         800  115.1274   \n",
       "21       138            6   21             6         500  133.7016   \n",
       "22       139            5   18            20         800   99.5088   \n",
       "23       140            5   26            10         500   83.9172   \n",
       "24       141            4   17            14         500  216.6936   \n",
       "25       142            4   23            20         800  129.8598   \n",
       "26       144            6   18            70        2520  267.5586   \n",
       "27       149            5   25             6         800   74.1174   \n",
       "28       154            5   25            20         700  101.6796   \n",
       "29       158            6   18            10         160  150.5004   \n",
       "...      ...          ...  ...           ...         ...       ...   \n",
       "3307    9213            5   34             4         364   77.5512   \n",
       "3308    9215            4   29             8         700  107.2092   \n",
       "3309    9216            2   30             2         240   54.8400   \n",
       "3310    9218            4   16            10         350  129.9708   \n",
       "3311    9219            2   19             4         400   80.4000   \n",
       "3312    9223            5   18            14         730  233.4966   \n",
       "3313    9224            1   25             4         200   74.3232   \n",
       "3314    9225            5   26             4         300  146.3508   \n",
       "3315    9228            3   19            20         500   49.0470   \n",
       "3316    9230            3   28            28          56  100.5414   \n",
       "3317    9232            2   27            16         400   61.3848   \n",
       "3318    9234            6   22            12        1000  209.1480   \n",
       "3319    9236            4   27            12        1200   65.6622   \n",
       "3320    9237            4   21            28         730  173.9034   \n",
       "3321    9240            2   31             8         750   89.2404   \n",
       "3322    9243            2   31            12          60   95.5152   \n",
       "3323    9244            6   23             4         600   88.5822   \n",
       "3324    9245            5   16            20         500  131.0706   \n",
       "3325    9246            6   20            20         830  152.1852   \n",
       "3326    9247            5   24             4         200  117.6942   \n",
       "3327    9251            3   30             6         650   53.6844   \n",
       "3328    9253            4   19            12         500  216.4782   \n",
       "3329    9255            6   24            14        2000  278.2188   \n",
       "3330    9256            4   21             6         560   88.4742   \n",
       "3331    9260            4   23            36        1500   96.6198   \n",
       "3332    9261            4   20             8         400  158.1390   \n",
       "3333    9264            5   16            56        1500  186.1320   \n",
       "3334    9265            4   21             8         100  121.6992   \n",
       "3335    9270            3   20            28         400  134.2848   \n",
       "3336    9271            4   22             6         400   88.8246   \n",
       "\n",
       "      SelectByHotkeys  AssignToHotkeys  UniqueHotkeys  MinimapAttacks  \\\n",
       "0            0.003515         0.000220              7        0.000110   \n",
       "1            0.003304         0.000259              4        0.000294   \n",
       "2            0.001101         0.000336              4        0.000294   \n",
       "3            0.001034         0.000213              1        0.000053   \n",
       "4            0.001136         0.000327              2        0.000000   \n",
       "5            0.000978         0.000255              2        0.000000   \n",
       "6            0.000820         0.000169              6        0.000000   \n",
       "7            0.009040         0.000676              6        0.001164   \n",
       "8            0.002944         0.000527              2        0.000019   \n",
       "9            0.005054         0.000524              8        0.000025   \n",
       "10           0.001677         0.000319              4        0.000000   \n",
       "11           0.000379         0.000255              3        0.000016   \n",
       "12           0.000423         0.000169              1        0.000024   \n",
       "13           0.004952         0.000052              2        0.000087   \n",
       "14           0.004254         0.000432              2        0.000775   \n",
       "15           0.002333         0.000430              4        0.000000   \n",
       "16           0.000664         0.000221              1        0.000018   \n",
       "17           0.003430         0.000634              7        0.000000   \n",
       "18           0.006701         0.000706              5        0.000013   \n",
       "19           0.002630         0.000287              5        0.000244   \n",
       "20           0.002651         0.000660              8        0.000099   \n",
       "21           0.004500         0.000420              3        0.000019   \n",
       "22           0.000734         0.000108              1        0.000024   \n",
       "23           0.002854         0.000493              3        0.000000   \n",
       "24           0.012495         0.000482              4        0.000054   \n",
       "25           0.002315         0.000334              5        0.000078   \n",
       "26           0.027815         0.000708             10        0.000000   \n",
       "27           0.000875         0.000205              6        0.000018   \n",
       "28           0.001406         0.000427              5        0.000000   \n",
       "29           0.005667         0.000632              6        0.000376   \n",
       "...               ...              ...            ...             ...   \n",
       "3307         0.002448         0.000486              7        0.000178   \n",
       "3308         0.002609         0.000444              3        0.000000   \n",
       "3309         0.001250         0.000360              4        0.000095   \n",
       "3310         0.003898         0.000738              4        0.000046   \n",
       "3311         0.000513         0.000053              1        0.000011   \n",
       "3312         0.014179         0.000576              6        0.000079   \n",
       "3313         0.000754         0.000117              2        0.000010   \n",
       "3314         0.005753         0.000300              6        0.000108   \n",
       "3315         0.000465         0.000452              2        0.000000   \n",
       "3316         0.000279         0.000102              3        0.000051   \n",
       "3317         0.000453         0.000117              4        0.000369   \n",
       "3318         0.021344         0.000602              5        0.000248   \n",
       "3319         0.001355         0.000226              2        0.000000   \n",
       "3320         0.008175         0.000165              5        0.000013   \n",
       "3321         0.000605         0.000052              2        0.000000   \n",
       "3322         0.002114         0.000278              6        0.000041   \n",
       "3323         0.003338         0.000517              4        0.000009   \n",
       "3324         0.003588         0.000117              4        0.000044   \n",
       "3325         0.011256         0.000622              5        0.000107   \n",
       "3326         0.003506         0.000546              6        0.000201   \n",
       "3327         0.003303         0.000458              5        0.000000   \n",
       "3328         0.017363         0.000617              3        0.000060   \n",
       "3329         0.026177         0.000455              2        0.000091   \n",
       "3330         0.002332         0.000522              3        0.000065   \n",
       "3331         0.001471         0.000371              3        0.000000   \n",
       "3332         0.013829         0.000504              7        0.000217   \n",
       "3333         0.006951         0.000360              6        0.000083   \n",
       "3334         0.002956         0.000241              8        0.000055   \n",
       "3335         0.005424         0.000182              5        0.000000   \n",
       "3336         0.000844         0.000108              2        0.000000   \n",
       "\n",
       "      MinimapRightClicks  NumberOfPACs  GapBetweenPACs  ActionLatency  \\\n",
       "0               0.000392      0.004849         32.6677        40.8673   \n",
       "1               0.000432      0.004307         32.9194        42.3454   \n",
       "2               0.000461      0.002926         44.6475        75.3548   \n",
       "3               0.000543      0.003783         29.2203        53.7352   \n",
       "4               0.001329      0.002368         22.6885        62.0813   \n",
       "5               0.000000      0.002425         76.4405        98.7719   \n",
       "6               0.000045      0.001988         94.0227        90.5311   \n",
       "7               0.001253      0.004952         24.6117        41.7671   \n",
       "8               0.000414      0.005399         52.0140        46.4321   \n",
       "9               0.000399      0.003569         24.4632        52.1538   \n",
       "10              0.000822      0.003772         23.4107        48.0711   \n",
       "11              0.000165      0.003555         39.6381        65.5000   \n",
       "12              0.000145      0.002885         42.4370        68.0502   \n",
       "13              0.000035      0.002728         54.8718        79.2102   \n",
       "14              0.000406      0.004571         36.2897        46.8889   \n",
       "15              0.000249      0.002900         45.1654        64.7500   \n",
       "16              0.000148      0.002656         45.7902        76.8889   \n",
       "17              0.000095      0.005535         28.3636        37.7947   \n",
       "18              0.000466      0.003237         67.0744        71.3251   \n",
       "19              0.000345      0.003650         40.4427        59.9370   \n",
       "20              0.000693      0.004147         30.7660        49.4854   \n",
       "21              0.000075      0.003874         21.4686        50.5253   \n",
       "22              0.000578      0.002695         22.7265        68.7321   \n",
       "23              0.000000      0.004607         51.2082        52.0494   \n",
       "24              0.000107      0.004334         27.9255        45.1605   \n",
       "25              0.001008      0.003473         36.3934        57.5215   \n",
       "26              0.000128      0.005616         34.6035        40.6025   \n",
       "27              0.000045      0.003518         46.4122        71.8173   \n",
       "28              0.000125      0.003453         26.7979        54.5979   \n",
       "29              0.000410      0.004626         30.2222        45.5941   \n",
       "...                  ...           ...             ...            ...   \n",
       "3307            0.000340      0.002496         31.8431        65.8701   \n",
       "3308            0.000038      0.004187         33.5566        62.9165   \n",
       "3309            0.000455      0.001970         52.1553        97.3462   \n",
       "3310            0.000611      0.003771         32.7975        48.5749   \n",
       "3311            0.000481      0.002520         45.2596        85.1695   \n",
       "3312            0.000402      0.005570         28.2072        33.7304   \n",
       "3313            0.000636      0.002604         44.2868        77.9549   \n",
       "3314            0.000372      0.003188         31.3962        61.9098   \n",
       "3315            0.000116      0.002284         37.5909        83.0734   \n",
       "3316            0.000661      0.002592         39.9604        57.3725   \n",
       "3317            0.000084      0.002280         40.3259        76.5294   \n",
       "3318            0.000248      0.002619         50.9589        80.9730   \n",
       "3319            0.000203      0.003161         58.3597        73.8571   \n",
       "3320            0.001282      0.003529         44.3032        59.6978   \n",
       "3321            0.000026      0.003555         43.7527        60.5072   \n",
       "3322            0.001861      0.002065         29.6667        87.4466   \n",
       "3323            0.000172      0.002718         41.8625        65.7427   \n",
       "3324            0.000432      0.004760         24.6410        47.6308   \n",
       "3325            0.000053      0.003396         61.6421        64.3979   \n",
       "3326            0.000805      0.002845         35.9184        65.7374   \n",
       "3327            0.000016      0.001930         43.5214        98.7458   \n",
       "3328            0.000388      0.003940         36.8101        54.6162   \n",
       "3329            0.000328      0.004244         30.4828        47.4678   \n",
       "3330            0.000228      0.003433         34.0286        63.7720   \n",
       "3331            0.000286      0.002614         47.2967        82.3825   \n",
       "3332            0.000313      0.003583         36.3990        66.2718   \n",
       "3333            0.000166      0.005414         22.8615        34.7417   \n",
       "3334            0.000208      0.003690         35.5833        57.9585   \n",
       "3335            0.000480      0.003205         18.2927        62.4615   \n",
       "3336            0.000341      0.003099         45.1512        63.4435   \n",
       "\n",
       "      ActionsInPAC  TotalMapExplored  WorkersMade  UniqueUnitsMade  \\\n",
       "0           4.7508                28     0.001397                6   \n",
       "1           4.8434                22     0.001194                5   \n",
       "2           4.0430                22     0.000745                6   \n",
       "3           4.9155                19     0.000426                7   \n",
       "4           9.3740                15     0.001174                4   \n",
       "5           3.0965                16     0.000372                6   \n",
       "6           4.1017                15     0.000573                5   \n",
       "7           6.6104                45     0.002277                9   \n",
       "8           3.3746                29     0.001035                7   \n",
       "9           6.5664                27     0.001310                6   \n",
       "10          7.0044                24     0.001593                7   \n",
       "11          4.2269                19     0.000757                7   \n",
       "12          4.3222                16     0.000748                7   \n",
       "13          6.2293                21     0.001494                5   \n",
       "14          5.4361                28     0.001981                7   \n",
       "15          4.5312                15     0.001246                6   \n",
       "16          3.5000                13     0.000664                6   \n",
       "17          4.7671                29     0.002768               10   \n",
       "18          4.3786                27     0.001332                9   \n",
       "19          4.9961                16     0.001581                5   \n",
       "20          4.6790                30     0.000825                8   \n",
       "21          5.4892                29     0.001008               10   \n",
       "22          6.7054                23     0.001961                7   \n",
       "23          2.8663                31     0.000654                9   \n",
       "24          6.3395                18     0.001204                5   \n",
       "25          6.7587                36     0.000753               11   \n",
       "26          4.1629                36     0.000856               12   \n",
       "27          3.7944                34     0.000929                5   \n",
       "28          5.3144                22     0.001032                4   \n",
       "29          4.9077                14     0.001007                6   \n",
       "...            ...               ...          ...              ...   \n",
       "3307        4.9740                22     0.000713                6   \n",
       "3308        4.4921                35     0.001040               11   \n",
       "3309        5.2981                17     0.000473                6   \n",
       "3310        5.5657                17     0.001269                7   \n",
       "3311        5.8390                23     0.001484                8   \n",
       "3312        5.0392                25     0.000751                5   \n",
       "3313        5.2820                19     0.000539                7   \n",
       "3314        7.0414                29     0.001642                9   \n",
       "3315        3.9379                15     0.000710                7   \n",
       "3316        7.2353                15     0.000508                3   \n",
       "3317        4.7941                19     0.000604                3   \n",
       "3318        6.8784                14     0.001310                3   \n",
       "3319        3.5286                17     0.000542                6   \n",
       "3320        6.9820                20     0.001117                6   \n",
       "3321        4.4384                14     0.000798                6   \n",
       "3322        8.4704                22     0.000800                8   \n",
       "3323        5.1115                30     0.000466                9   \n",
       "3324        4.3754                26     0.000659                6   \n",
       "3325        5.0733                15     0.001049                5   \n",
       "3326        6.5859                20     0.001351                6   \n",
       "3327        3.7288                14     0.000638                4   \n",
       "3328        6.5126                24     0.001502                9   \n",
       "3329        6.0901                22     0.001494                7   \n",
       "3330        4.3420                29     0.000783                9   \n",
       "3331        6.0383                22     0.000514                5   \n",
       "3332        4.5097                30     0.001035                7   \n",
       "3333        4.9309                38     0.001343                7   \n",
       "3334        5.4154                23     0.002014                7   \n",
       "3335        6.0202                18     0.000934                5   \n",
       "3336        5.1913                20     0.000476                8   \n",
       "\n",
       "      ComplexUnitsMade  ComplexAbilitiesUsed  \n",
       "0             0.000000              0.000000  \n",
       "1             0.000000              0.000208  \n",
       "2             0.000000              0.000189  \n",
       "3             0.000000              0.000384  \n",
       "4             0.000000              0.000019  \n",
       "5             0.000000              0.000000  \n",
       "6             0.000000              0.000000  \n",
       "7             0.000129              0.000249  \n",
       "8             0.000273              0.000470  \n",
       "9             0.000000              0.000000  \n",
       "10            0.000000              0.000017  \n",
       "11            0.000107              0.000263  \n",
       "12            0.000000              0.000435  \n",
       "13            0.000000              0.000000  \n",
       "14            0.000000              0.000000  \n",
       "15            0.000000              0.000227  \n",
       "16            0.000000              0.000295  \n",
       "17            0.000087              0.000102  \n",
       "18            0.000240              0.000000  \n",
       "19            0.000000              0.000000  \n",
       "20            0.000000              0.000517  \n",
       "21            0.000000              0.000560  \n",
       "22            0.000000              0.000000  \n",
       "23            0.000000              0.000000  \n",
       "24            0.000000              0.000000  \n",
       "25            0.000284              0.001229  \n",
       "26            0.000089              0.000197  \n",
       "27            0.000000              0.000000  \n",
       "28            0.000000              0.000570  \n",
       "29            0.000000              0.000000  \n",
       "...                ...                   ...  \n",
       "3307          0.000000              0.000000  \n",
       "3308          0.000113              0.000123  \n",
       "3309          0.000000              0.000000  \n",
       "3310          0.000173              0.000657  \n",
       "3311          0.000000              0.000000  \n",
       "3312          0.000210              0.000812  \n",
       "3313          0.000000              0.000078  \n",
       "3314          0.000132              0.000144  \n",
       "3315          0.000000              0.000013  \n",
       "3316          0.000000              0.000000  \n",
       "3317          0.000000              0.000000  \n",
       "3318          0.000000              0.000000  \n",
       "3319          0.000000              0.000113  \n",
       "3320          0.000267              0.000089  \n",
       "3321          0.000000              0.000039  \n",
       "3322          0.000000              0.000000  \n",
       "3323          0.000131              0.000303  \n",
       "3324          0.000000              0.000000  \n",
       "3325          0.000000              0.000000  \n",
       "3326          0.000000              0.000000  \n",
       "3327          0.000000              0.000000  \n",
       "3328          0.000000              0.000010  \n",
       "3329          0.000000              0.000000  \n",
       "3330          0.000204              0.000228  \n",
       "3331          0.000000              0.000000  \n",
       "3332          0.000000              0.000287  \n",
       "3333          0.000000              0.000388  \n",
       "3334          0.000000              0.000000  \n",
       "3335          0.000000              0.000000  \n",
       "3336          0.000000              0.000054  \n",
       "\n",
       "[3337 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "star_craft_csv = pd.read_csv('SkillCraft.csv')\n",
    "star_craft_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GameID' 'LeagueIndex' 'Age' 'HoursPerWeek' 'TotalHours' 'APM'\n",
      " 'SelectByHotkeys' 'AssignToHotkeys' 'UniqueHotkeys' 'MinimapAttacks'\n",
      " 'MinimapRightClicks' 'NumberOfPACs' 'GapBetweenPACs' 'ActionLatency'\n",
      " 'ActionsInPAC' 'TotalMapExplored' 'WorkersMade' 'UniqueUnitsMade'\n",
      " 'ComplexUnitsMade' 'ComplexAbilitiesUsed']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('SkillCraft.csv', 'r') as csvfile:\n",
    "    sc_reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    \n",
    "    sc_X, sc_y = [], []\n",
    "\n",
    "    for row in sc_reader:\n",
    "        sc_X.append(row)\n",
    "        sc_y.append(row[1]) # The target value is \"level\"\n",
    "        \n",
    "    feature_names = np.array(sc_X[0])\n",
    "\n",
    "    sc_X = np.array(sc_X[1:])\n",
    "    sc_y = np.array(sc_y[1:])\n",
    "\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['52' '5' '27' ... '6' '0' '0']\n",
      " ['55' '5' '23' ... '5' '0' '0.00020757']\n",
      " ['56' '4' '30' ... '6' '0' '0.00018876']\n",
      " ...\n",
      " ['9265' '4' '21' ... '7' '0' '0']\n",
      " ['9270' '3' '20' ... '5' '0' '0']\n",
      " ['9271' '4' '22' ... '8' '0' '5.3891e-05']]\n"
     ]
    }
   ],
   "source": [
    "print(sc_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5' '5' '4' ... '4' '3' '4']\n"
     ]
    }
   ],
   "source": [
    "print(sc_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GameID' 'LeagueIndex' 'Age' 'HoursPerWeek' 'TotalHours' 'APM'\n",
      " 'SelectByHotkeys' 'AssignToHotkeys' 'UniqueHotkeys' 'MinimapAttacks'\n",
      " 'MinimapRightClicks' 'NumberOfPACs' 'GapBetweenPACs' 'ActionLatency'\n",
      " 'ActionsInPAC' 'TotalMapExplored' 'WorkersMade' 'UniqueUnitsMade'\n",
      " 'ComplexUnitsMade' 'ComplexAbilitiesUsed'] ['52' '5' '27' '10' '3000' '143.718' '0.0035151591' '0.0002196974' '7'\n",
      " '0.0001098487' '0.0003923169' '0.0048490365' '32.6677' '40.8673' '4.7508'\n",
      " '28' '0.0013966' '6' '0' '0'] 5\n"
     ]
    }
   ],
   "source": [
    "print (feature_names, sc_X[0], sc_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HoursPerWeek' 'TotalHours' 'APM' 'SelectByHotkeys' 'AssignToHotkeys'\n",
      " 'UniqueHotkeys' 'MinimapAttacks' 'MinimapRightClicks' 'NumberOfPACs'\n",
      " 'GapBetweenPACs' 'ActionLatency' 'ActionsInPAC' 'TotalMapExplored'\n",
      " 'WorkersMade' 'UniqueUnitsMade' 'ComplexUnitsMade' 'ComplexAbilitiesUsed']\n"
     ]
    }
   ],
   "source": [
    "# 保留主要信息\n",
    "\n",
    "sc_X = sc_X[:, [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "feature_names = feature_names[[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "\n",
    "print (feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['10' '3000' '143.718' '0.0035151591' '0.0002196974' '7' '0.0001098487'\n",
      "  '0.0003923169' '0.0048490365' '32.6677' '40.8673' '4.7508' '28'\n",
      "  '0.0013966' '6' '0' '0']\n",
      " ['10' '5000' '129.2322' '0.0033038124' '0.0002594617' '4' '0.0002940566'\n",
      "  '0.0004324362' '0.0043070643' '32.9194' '42.3454' '4.8434' '22'\n",
      "  '0.0011935' '5' '0' '0.00020757']\n",
      " ['10' '200' '69.9612' '0.0011010906' '0.0003355705' '4' '0.0002936242'\n",
      "  '0.0004614094' '0.002925755' '44.6475' '75.3548' '4.043' '22'\n",
      "  '0.00074455' '6' '0' '0.00018876']\n",
      " ['20' '400' '107.6016' '0.0010335422' '0.0002131015' '1'\n",
      "  '5.32753697310659e-05' '0.0005434088' '0.0037825513' '29.2203'\n",
      "  '53.7352' '4.9155' '19' '0.0004262' '7' '0' '0.00038358']\n",
      " ['10' '500' '122.8908' '0.0011360136' '0.0003273259' '2' '0'\n",
      "  '0.0013285582' '0.0023682994' '22.6885' '62.0813' '9.374' '15'\n",
      "  '0.0011745' '4' '0' '1.9254e-05']\n",
      " ['6' '70' '44.457' '0.0009783903' '0.0002552323' '2' '0' '0'\n",
      "  '0.0024247065' '76.4405' '98.7719' '3.0965' '16' '0.00037221' '6' '0'\n",
      "  '0']\n",
      " ['8' '240' '46.9962' '0.0008201141' '0.0001685166' '6' '0'\n",
      "  '4.4937761200737e-05' '0.0019884959' '94.0227' '90.5311' '4.1017' '15'\n",
      "  '0.00057296' '5' '0' '0']\n",
      " ['42' '10000' '212.6022' '0.0090397391' '0.0006762401' '6'\n",
      "  '0.0011635308' '0.0012530331' '0.0049524643' '24.6117' '41.7671'\n",
      "  '6.6104' '45' '0.0022773' '9' '0.0001292812' '0.00024862']\n",
      " ['14' '2708' '117.4884' '0.0029442751' '0.0005267713' '2'\n",
      "  '1.88132595853558e-05' '0.0004138917' '0.0053994055' '52.014' '46.4321'\n",
      "  '3.3746' '29' '0.0010347' '7' '0.0002727923' '0.00047033']\n",
      " ['24' '800' '155.9856' '0.0050539084' '0.000524109' '8'\n",
      "  '2.49575721273834e-05' '0.0003993212' '0.0035689328' '24.4632'\n",
      "  '52.1538' '6.5664' '27' '0.0013103' '6' '0' '0']\n",
      " ['16' '6000' '153.801' '0.0016766146' '0.0003185568' '4' '0'\n",
      "  '0.0008215411' '0.0037723828' '23.4107' '48.0711' '7.0044' '24'\n",
      "  '0.0015928' '7' '0' '1.6766e-05']\n",
      " ['4' '190' '79.2948' '0.0003785385' '0.000255102' '3'\n",
      "  '1.64581961816985e-05' '0.000164582' '0.0035549704' '39.6381' '65.5'\n",
      "  '4.2269' '19' '0.00075708' '7' '0.0001069783' '0.00026333']\n",
      " ['12' '350' '67.4754' '0.0004225216' '0.0001690086' '1'\n",
      "  '2.41440919407021e-05' '0.0001448646' '0.002885219' '42.437' '68.0502'\n",
      "  '4.3222' '16' '0.00074847' '7' '0' '0.00043459']\n",
      " ['6' '1000' '119.4366' '0.0049520434' '5.21267723102585e-05' '2'\n",
      "  '8.68779538504309e-05' '3.47511815401724e-05' '0.0027279678' '54.8718'\n",
      "  '79.2102' '6.2293' '21' '0.0014943' '5' '0' '0']\n",
      " ['30' '5000' '160.4754' '0.0042538602' '0.0004317351' '2' '0.0007745835'\n",
      "  '0.0004063389' '0.0045713125' '36.2897' '46.8889' '5.4361' '28'\n",
      "  '0.0019809' '7' '0' '0']\n",
      " ['16' '1500' '81.7722' '0.0023334844' '0.0004304486' '4' '0'\n",
      "  '0.0002492071' '0.0028998641' '45.1654' '64.75' '4.5312' '15'\n",
      "  '0.001246' '6' '0' '0.00022655']\n",
      " ['8' '2000' '50.8374' '0.0006641086' '0.0002213695' '1'\n",
      "  '1.84474616292798e-05' '0.0001475797' '0.0026564345' '45.7902'\n",
      "  '76.8889' '3.5' '13' '0.00066411' '6' '0' '0.00029516']\n",
      " ['10' '120' '160.6464' '0.0034303443' '0.0006336305' '7' '0'\n",
      "  '9.46804171764843e-05' '0.0055351629' '28.3636' '37.7947' '4.7671' '29'\n",
      "  '0.0027676' '10' '8.73973081629086e-05' '0.00010196']\n",
      " ['14' '350' '107.9118' '0.0067013056' '0.0007061018' '5'\n",
      "  '1.33226751931788e-05' '0.0004662936' '0.0032374101' '67.0744'\n",
      "  '71.3251' '4.3786' '27' '0.0013323' '9' '0.0002398082' '0']\n",
      " ['28' '1100' '114.7806' '0.0026296126' '0.0002873894' '5' '0.000244281'\n",
      "  '0.0003448672' '0.0036498448' '40.4427' '59.937' '4.9961' '16'\n",
      "  '0.0015806' '5' '0' '0']] ['5' '5' '4' '3' '3' '2' '1' '7' '4' '4' '3' '4' '3' '3' '5' '5' '4' '5'\n",
      " '5' '4']\n"
     ]
    }
   ],
   "source": [
    "print (sc_X[:20], sc_y[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3337, 17) (3337,)\n"
     ]
    }
   ],
   "source": [
    "print(sc_X.shape, sc_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入分解数据模块\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sc_X, sc_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2502, 17) (2502,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=33)\n",
    "print (X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入标准化函数\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U20 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U20 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# 特征标准化\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colors = ['red', 'greenyellow', 'blue']\n",
    "#for i in range(len(colors)):\n",
    "#    px = X_train[:, 0][y_train == i]\n",
    "#    py = X_train[:, 1][y_train == i]\n",
    "#    plt.scatter(px, py, c=colors[i])\n",
    "#\n",
    "#plt.legend(feature_names)\n",
    "#plt.xlabel('APM')\n",
    "#plt.ylabel('ACTIONINPAC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检验模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建对象 线性模型分类器 linear model classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 拟合（训练）分类器\n",
    "clf.fit(X_train, y_train) # 注意参数设置警告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.42121633 -17.69282171  -7.59665013 -14.50698881  -3.24884569\n",
      "   -1.16018359  -6.89178067  -1.80477967  -0.46017644  -1.3953837\n",
      "   -2.0991645    1.34651679   3.41202542  -4.55221129   1.12612344\n",
      "   -1.63867048  -7.24311426]\n",
      " [ -0.69590593  -7.21173598  -3.61556418  -2.47282751  -4.37822818\n",
      "   -3.69149325  -5.90126729  -1.67310211  -3.48161168  -5.69229102\n",
      "   -3.69466173  -1.26917671  -0.33156062  -0.69322553  -0.72622165\n",
      "    2.31201711  -2.87004794]\n",
      " [ -2.05173022  -0.79058735  -7.57386304  -1.49650571   1.022582\n",
      "   -3.79696449  -3.75423654   0.34455436  -0.4604971    1.41461922\n",
      "    0.98769344  -0.90563266   0.80431787  -2.61954402  -0.28025117\n",
      "   -3.81940794  -1.64289052]\n",
      " [ -2.37825156  -2.79729244  -2.13632425  -2.43411968   1.61272433\n",
      "    0.31641371  -2.71415047   1.94479955  -4.48069657  -3.51745726\n",
      "   -6.63854961  -0.21299897   1.02940235  -1.168498     1.19490654\n",
      "    0.33536574   1.72864254]\n",
      " [ -3.19104394   3.21269362  -2.16982299   0.5959808    0.20776751\n",
      "    0.63282741  -0.59424078   2.49107008  -1.76317283  -2.61198685\n",
      "   -7.43041941  -0.75880611   0.41760356   1.82744226   1.85810367\n",
      "    1.70203802   1.65155505]\n",
      " [  5.37692294  -0.6941508    1.06107118   7.10532479   2.9557638\n",
      "   -0.10547124   0.0668721   -1.13238046   1.94285481  -3.2381376\n",
      "   -7.99485298  -0.37608723   1.94019636  -4.68676618  -2.23561096\n",
      "   -0.25988084   1.28457074]\n",
      " [  7.5987895    3.37717135   3.07808074   2.41432494  21.53826031\n",
      "   15.9261566   10.95742299   2.91603239  14.66471004 -22.95354081\n",
      "  -16.44627142  -4.38904248  11.08956152   0.04915754 -10.72024723\n",
      "    0.69505667   3.78893351]]\n",
      "[ -44.8292536   -15.55580068   -5.18827181   -8.10388213   -4.87832938\n",
      "  -12.56701017 -169.70743587]\n"
     ]
    }
   ],
   "source": [
    "# 输出 学习得到的系数\n",
    "print (clf.coef_)\n",
    "print (clf.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3405275779376499"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 根据模型得到的预测值\n",
    "y_train_pred = clf.predict(X_train)\n",
    "\n",
    "# 与人工值比较，并输出得分\n",
    "train_score = metrics.accuracy_score(y_train, y_train_pred)\n",
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U20 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3221556886227545"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试集也要标准化\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 预测\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 与人工值比较，并输出得分\n",
    "test_score = metrics.accuracy_score(y_test, y_pred)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  K-折交叉检验分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入函数等\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建管线实现的复合估计器\n",
    "clf = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('linear_model', SGDClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 k-折交叉验证迭代器，取 k=5\n",
    "cv = KFold( 5,shuffle = True, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U20 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U20 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U20 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U20 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U20 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U20 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U20 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U20 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U20 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U20 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U20 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U20 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34281437 0.32035928 0.24137931 0.34932534 0.30284858]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U20 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U20 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U20 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# 得分\n",
    "cross_scores = cross_val_score(clf, X, y, cv=cv)\n",
    "print(cross_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 交叉验证精度的均值和标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 0.311 (+/-0.019)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import sem\n",
    "\n",
    "def mean_score(scores):\n",
    "    \"\"\"Print the empirical mean score and standard error of the mean.\"\"\"\n",
    "    return (\"Mean score: {0:.3f} (+/-{1:.3f})\").format(\n",
    "        np.mean(scores), sem(scores))\n",
    "\n",
    "print(mean_score(cross_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、利用回归方法预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2502, 17), (835, 17), (2502,), (835,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换为二维数组\n",
    "y_train = y_train.reshape(-1,1) # 1 列\n",
    "y_test  = y_test.reshape(-1,1)  # 1 列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入标准化器\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U20 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U1 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scalerX = StandardScaler().fit(X_train)\n",
    "scalery = StandardScaler().fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U20 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U1 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# 训练样本集、训练目标集 标准化\n",
    "X_train = scalerX.transform(X_train)\n",
    "y_train = scalery.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U20 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype <U1 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# 测试样本集、测试目标集 标准化\n",
    "X_test = scalerX.transform(X_test)\n",
    "y_test = scalery.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转为一维数组\n",
    "y_train = y_train.reshape(-1,)\n",
    "y_test  = y_test.reshape(-1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立线性回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(clf, X_train, y_train):\n",
    "    clf.fit(X_train, y_train)  # 训练\n",
    "    print (\"在训练集上，决定系数：\",clf.score(X_train, y_train))\n",
    "\n",
    "    # 创建 K-折\n",
    "    cv = KFold(5, shuffle=True, random_state=33)                    # ms\n",
    "    #cv = KFold(X_train.shape[0], 5, shuffle=True, random_state=33) # cv\n",
    "\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=cv)\n",
    "    print (\"使用 K-折交叉验证的 平均决定系数:\",np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在训练集上，决定系数： 0.5487036800304088\n",
      "使用 K-折交叉验证的 平均决定系数: 0.5364564611616339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf_sgd = linear_model.SGDRegressor(loss='squared_loss', penalty=None, max_iter=5, tol=None, random_state=42)\n",
    "train_and_evaluate(clf_sgd, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.53071819e-02  8.89282321e-02  5.67015529e-02  7.59342924e-02\n",
      "  1.26975424e-01  4.09743965e-02  1.14582249e-01  3.06114561e-05\n",
      "  1.50272566e-01 -1.34786295e-01 -2.26921720e-01  1.34353551e-02\n",
      " -1.82452041e-02  6.67159026e-02 -2.35380351e-02  1.24703502e-02\n",
      "  6.46602644e-03] \n",
      "\n",
      "[-0.01251698]\n"
     ]
    }
   ],
   "source": [
    "print(clf_sgd.coef_, \"\\n\")\n",
    "print(clf_sgd.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在训练集上，决定系数： 0.54870292835222\n",
      "使用 K-折交叉验证的 平均决定系数: 0.5364582747942068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf_sgd_l2 = linear_model.SGDRegressor(loss='squared_loss', penalty='l2', max_iter=5, tol=None, random_state=42)\n",
    "train_and_evaluate(clf_sgd_l2, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  比较两次结果得分\n",
    "\n",
    "\n",
    "- 几乎没有变化\n",
    "- 说明对于本例\n",
    "    - <font color=\"red\">线性回归模型效果一般</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将支持向量机 SVM 用于回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入模块 svm\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在训练集上，决定系数： 0.5345100139319723\n",
      "使用 K-折交叉验证的 平均决定系数: 0.5168210574881118\n"
     ]
    }
   ],
   "source": [
    "clf_svr = svm.SVR(kernel='linear')\n",
    "train_and_evaluate(clf_svr, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在训练集上，决定系数： 0.5508667566932626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用 K-折交叉验证的 平均决定系数: -2.923700255810707\n"
     ]
    }
   ],
   "source": [
    "clf_svr_poly = svm.SVR(kernel='poly')\n",
    "train_and_evaluate(clf_svr_poly, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在训练集上，决定系数： 0.6950436293055504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用 K-折交叉验证的 平均决定系数: 0.5629450366107253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf_svr_rbf = svm.SVR(kernel='rbf')\n",
    "train_and_evaluate(clf_svr_rbf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.5.6 将`极端随机森林`用于回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 ensemble\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_et=ensemble.ExtraTreesRegressor(n_estimators=10, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在训练集上，决定系数： 1.0\n",
      "使用 K-折交叉验证的 平均决定系数: 0.5417181367312038\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(clf_et, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.22309520429558863, 'ActionLatency'), (0.14373317556149065, 'APM'), (0.0889273754687495, 'GapBetweenPACs'), (0.08594488294261401, 'NumberOfPACs'), (0.07819917222530212, 'TotalHours'), (0.0704764435790732, 'AssignToHotkeys'), (0.055455961285549346, 'SelectByHotkeys'), (0.036470361878926126, 'MinimapAttacks'), (0.030180315046350548, 'WorkersMade'), (0.027545910378133615, 'HoursPerWeek'), (0.026560303494042897, 'UniqueUnitsMade'), (0.025460246660333762, 'UniqueHotkeys'), (0.024035810840080964, 'TotalMapExplored'), (0.023491586192466374, 'ActionsInPAC'), (0.023376515817469946, 'MinimapRightClicks'), (0.022416450785676497, 'ComplexAbilitiesUsed'), (0.014630283548151782, 'ComplexUnitsMade')]\n"
     ]
    }
   ],
   "source": [
    "# 特征重要性\n",
    "feature_importance = zip(clf_et.feature_importances_,  feature_names)\n",
    "print (sorted(feature_importance, key=lambda x: x[0], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def measure_performance(X,y,clf, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True, show_r2_score=False):\n",
    "    y_pred=clf.predict(X)   \n",
    "    if show_accuracy:\n",
    "        print (\"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y,y_pred)),\"\\n\")\n",
    "\n",
    "    if show_classification_report:\n",
    "        print (\"分类报告\")\n",
    "        print (metrics.classification_report(y,y_pred),\"\\n\")\n",
    "        \n",
    "    if show_confusion_matrix:\n",
    "        print (\"混淆矩阵\")\n",
    "        print (metrics.confusion_matrix(y,y_pred),\"\\n\")\n",
    "        \n",
    "    if show_r2_score:\n",
    "        print (\"决定系数:{0:.3f}\".format(metrics.r2_score(y,y_pred)),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决定系数:0.523 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_performance(X_test, y_test,\n",
    "                    clf_et,\n",
    "                    show_accuracy=False,\n",
    "                    show_classification_report=False,\n",
    "                    show_confusion_matrix=False,\n",
    "                    show_r2_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
